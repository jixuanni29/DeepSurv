# ------------------------------------------------------------------------------
# --coding='utf-8'--
# Written by czifan (czifan@pku.edu.cn)
# ------------------------------------------------------------------------------
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import torch
import torch.optim as optim
from networks import DeepSurv
from networks import NegativeLogLikelihood
from datasets import SurvivalDataset
from utils import read_config
from utils import c_index
from utils import adjust_learning_rate
from utils import create_logger
import pandas as pd
from sklearn.model_selection import train_test_split

def train(ini_file):
    ''' Performs training according to .ini file

    :param ini_file: (String) the path of .ini file
    :return best_c_index: the best c-index
    '''
    # reads configuration from .ini file
    config = read_config(ini_file)
    # builds network|criterion|optimizer based on configuration
    model = DeepSurv(config['network']).to(device)
    criterion = NegativeLogLikelihood(config['network']).to(device)
    optimizer = eval('optim.{}'.format(config['train']['optimizer']))(
        model.parameters(), lr=config['train']['learning_rate'])
    # constructs data loaders based on configuration
    dataset = SurvivalDataset(config['train']['h5_file'], is_train=True)
    train_dataset, test_dataset = train_test_split(dataset, test_size=0.1, )
    # test_dataset = SurvivalDataset(config['train']['h5_file'], is_train=False)
    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=train_dataset.__len__())
    test_loader = torch.utils.data.DataLoader(
        test_dataset, batch_size=test_dataset.__len__())
    # training
    best_c_index = 0
    flag = 0
    for epoch in range(1, config['train']['epochs']+1):
        # adjusts learning rate
        lr = adjust_learning_rate(optimizer, epoch,
                                  config['train']['learning_rate'],
                                  config['train']['lr_decay_rate'])
        # train step
        model.train()
        for X, y, e in train_loader:
            # makes predictions
            risk_pred, layer_outputs = model(X)
            train_loss = criterion(risk_pred, y, e, model)
            train_c = c_index(-risk_pred, y, e)
            if best_c_index < train_c:
                best_c_index = train_c

            # updates parameters
            optimizer.zero_grad()
            train_loss.backward()
            optimizer.step()
        # valid step
        model.eval()
        for X, y, e in test_loader:
            # makes predictions
            with torch.no_grad():
                risk_pred, layer_outputs = model(X)
                valid_loss = criterion(risk_pred, y, e, model)
                valid_c = c_index(-risk_pred, y, e)
                # if best_c_index < valid_c:
                #     best_c_index = valid_c
                #     flag = 0
                #     # saves the best model
                #     torch.save({
                #         'model': model.state_dict(),
                #         'optimizer': optimizer.state_dict(),
                #         'epoch': epoch}, os.path.join(models_dir, ini_file.split('\\')[-1]+'.pth'))
                # else:
                #     flag += 1
                #     if flag >= patience:
                #         return best_c_index
        # notes that, train loader and valid loader both have one batch!!!
        print('\rEpoch: {}\tLoss: {:.8f}({:.8f})\tc-index: {:.8f}({:.8f})\tlr: {:g}'.format(
            epoch, train_loss.item(), valid_loss.item(), train_c, valid_c, lr), end='', flush=False)
    return best_c_index

if __name__ == '__main__':
    # global settings
    logs_dir = 'logs'
    models_dir = os.path.join(logs_dir, 'models')
    if not os.path.exists(models_dir):
        os.makedirs(models_dir)
    logger = create_logger(logs_dir)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    configs_dir = 'configs'
    params = [
        ('TLS', 'x_TLS.ini'),
        ('CAF', 'x_CAF.ini'),
        ('CAF + TLS', 'x_CAF_TLS.ini')]
        # ('WHAS', 'whas.ini'),
        # ('SUPPORT', 'support.ini'),
        # ('METABRIC', 'metabric.ini'),
        # ('Simulated Treatment', 'treatment.ini'),
        # ('Rotterdam & GBSG', 'gbsg.ini')]
    patience = 100
    # training
    headers = []
    values = []
    for name, ini_file in params:
        logger.info('Running {}({})...'.format(name, ini_file))
        for i in range(20):
            best_c_index = train(os.path.join(configs_dir, ini_file))
            logger.info("The best valid c-index: {}".format(best_c_index))
            headers.append(name)
            values.append('{:.6f}'.format(best_c_index))

    result = {
        "Model" : headers,
        "C_index": values
    }

    df = pd.DataFrame(result)
    df.to_csv('deepsurv_results.csv', index=False)





